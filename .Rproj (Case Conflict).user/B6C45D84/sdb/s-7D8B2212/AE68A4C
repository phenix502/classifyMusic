{
    "contents" : "基于随机森林算法的歌词分类研究\n========================================================\n\n本文档详细介绍如何使用R语言，进行文本情感分类研究。\n\n## 1 加载包\n\n各个package的主要功能如下：\n\n+ tm 形成文档词条矩阵\n+ Rwordseg 中文分词\n+ FSelector 特征提取，有chi-square，information gain等等\n+ RTextTools 文本挖掘分类算法,我这里用到的是随机森林和SVM\n\n```{r}\nlibrary(tm)\nlibrary(Rwordseg)\nlibrary(RTextTools)\nlibrary(FSelector)\n\n```\n\n## 2 读取歌词文本\n\n读入工作目录下的`sweetsong.csv`和`sadsong.csv`文件，分别为甜蜜歌词和伤感歌词。甜蜜歌词来自于百度音乐[甜蜜标签](http://music.baidu.com/tag/%E7%94%9C%E8%9C%9C)下的所有歌曲,\n伤感歌词来自于百度音乐[伤感标签](http://music.baidu.com/tag/%E4%BC%A4%E6%84%9F)下的所有歌曲。采用python的scrapy爬虫框架抓取这些资料，源代码在[这里](https://github.com/phenix502/baidu)。\n\n\n\n```{r}\n# 防止读入的所有string都被当成factor\noptions(stringsAsFactors=FALSE)\n# 读入csv文件\nInfor.sweet <- read.csv('material/sweetsong.csv', header=TRUE)\nInfor.sad <- read.csv('material/sadsong.csv', header=TRUE)\n\n```\n\n## 3 分词并形成语料库\n使用中文分词包Rwordseg对歌词进行分词。并把分好的词合成语料库。\n```{r}\n## 由两个character类型的变量\n## 形成语料库\nremoveEnglish <- function(x){\n  gsub(\"[a-z]+|[A-Z]+\",\"\",x)\n}\n\nmakeCorpus <- function(str1, str2){\n# 伤感歌曲分词   组成语料库\nword.sad <- lapply(str1,removeEnglish)\nword.sad <- lapply(word.sad,segmentCN)\ncorpus.sad <- Corpus(VectorSource(word.sad))\n\n# 甜蜜歌曲分词   组成语料库\nword.sweet <- lapply(str2, removeEnglish)\nword.sweet <- lapply(word.sweet, segmentCN)\ncorpus.sweet <- Corpus(VectorSource(word.sweet))\n\n# 合成预料库\ncorpus <- c(corpus.sad, corpus.sweet)\nreturn(corpus)\n}\n\ncorpus <- makeCorpus(Infor.sweet$lyric, Infor.sad$lyric)\n```\n\n\n\n\n\n## 3 document-term matrix 函数实现\n要将文本信息转为可以给各种分类计算的信息，首先要把文本信息转为各种能计算的数字。document-term matrix每一列是一个词语，每一行是词频数，当然一般用TF-IDF作为特征权值计算。document-term 矩阵就是分类算法的特征矩阵，只是没给每一个数据集标上所属的类别。\n\n```{r}\ndtm <- function(corpus, tfidf = FALSE){\n  \n  ## 读取停止词\n  mystopwords <- readLines(\"stopwords.txt\")\n  if (tfidf==TRUE){\n    ## 文档-词矩阵 词的长度大于1就纳入矩阵\n    cor.dtm <- DocumentTermMatrix(corpus, control=list( wordLengths = c(2, Inf),\n                                                     stopwords=mystopwords,\n                                                     weighting = weightTfIdf))\n  }\n  else{\n    cor.dtm <- DocumentTermMatrix(corpus, control=list( wordLengths = c(2, Inf),\n                                                     stopwords=mystopwords))\n  }\n  ##去掉稀疏矩阵中低频率的词\n  cor.dtm <- removeSparseTerms(cor.dtm, 0.98)\n  \n  ## 使得每一行至少有一个词不为0\n  #rowTotals <- apply(cor.dtm, 1, sum)\n  #cor.dtm <- cor.dtm[rowTotals > 0]\n  return (cor.dtm)\n}\n\n```\n\n利用`dtm`函数，形成为文本词条矩阵\n```{r}\ncorpus.dtm <- dtm(corpus)\ncorpus.dtm.tfidf <- dtm(corpus, tfidf=TRUE)\n```\n\n## 4 使用算法对歌词进行情感极性的分析\n\n首先对每一首标上对应的类别。数据集中前764首歌曲是伤感歌曲，后面861首是甜蜜的歌曲。然后确定测试集和训练集范围。\n\n```{r}\n# 类别向量\nlabel<-factor(c(rep(\"sad\",764),c(rep(\"sweet\",861))))\n\n#  从伤感歌词中挑选64首作为测试集，同理甜蜜类挑选61首作为测试集\nsad.test <- sample(1:764, 64, replace= FALSE)\nsweet.test <-sample(765:1625,61,replace= FALSE)\ntest <- c(sad.test,sweet.test)\ntrainSize <- 1:1625\ntrainSize <- trainSize[-test]\n\n```\n\n\n\n传入一个document-term matrix，然后使用SVM和随机森林算法对输入的数据进行分类。\n```{r}\n\n## 传入一个document-term matrix，使用SVM和随机森林进行分类\nalgorithom_summary <- function(dtm){\n# create a container\ncontainer.song <- create_container(dtm, label,\n                                   trainSize=trainSize, testSize=testSize, virgin=FALSE)\n\n# training models\nSVM.song <- train_model(container.song, \"SVM\")\nRF.song <- train_model(container.song, \"RF\")\n\n# classifying data using trained models\nSVM_CLASSIFY.song <- classify_model(container.song, SVM.song)\nRF_CLASSIFY.song <- classify_model(container.song, RF.song)\n\n\nSVM_result <- create_precisionRecallSummary(container=container.song, classification_results=SVM_CLASSIFY.song)\nRF_result <-create_precisionRecallSummary(container=container.song, classification_results=RF_CLASSIFY.song)\nreturn(list(SVM_RESULT=SVM_result,RF_RESULT=RF_result))\n}\n\n```\n\n使用algorithm_summary函数对歌曲进行分类，我们看一下分类结果。\n```{r}\nresult_all_corpus <- algorithm_summary(corpus.dtm.tfidf)\nresult_all_corpus\n```\n可以看出分类结果不是很好，这是因为document-term matrix是一个高维稀疏的矩阵，为了提高分类效果，可以尝试特征提取。\n\n\n## 5 特征提取\n\n采用随机森林算法选取前100个重要的词语，`subset`即是前100有重要分类信息的词语\n\n```{r}\n# 转为data frame\ncorpus.df <- as.data.frame(inspect(corpus.dtm.tfidf))\n\n## 随机森林算法选取前100个重要的词语\nweights.rf <- random.forest.importance(label~., corpus.df, 1)\nsubset <- cutoff.k(weights.rf, 100)\n## 把提取的特征作为新的docment-term matrix\nfeature.df <- as.DocumentTermMatrix(corpus.df[subset],weighting=weightTf)\n```\n让我们再次看看分类效果\n\n```{r}\nresult_feature <- algorithm_summary(feature.df)\nresult_feature\n```\n\n\n\n\n\n\n\n\n\n",
    "created" : 1392087766825.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "3477549389",
    "id" : "AE68A4C",
    "lastKnownWriteTime" : 1392094828,
    "path" : "~/GitHub/classifyMusic/readme.Rmd",
    "project_path" : "readme.Rmd",
    "properties" : {
    },
    "source_on_save" : false,
    "type" : "r_markdown"
}