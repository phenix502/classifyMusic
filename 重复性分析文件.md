歌词情感级性分析
========================================================

在R语言作数据分析之前，已经做的工作有：

1. 使用scrapy爬取数据到mongodb数据库
2. 从mongodb数据库中导出csv格式文件
3. 使用**google refine**进行数据清理，清除非中文歌曲和明显不属于伤感或甜蜜的歌曲

经过以上步骤得到，数据最终保存到当前工作目录下，**sadsong.csv**是伤感类歌曲文件，一共有764首。**sweetsong.csv**是甜蜜类文件，一共有861首。当前工作目录有以下文件：


```r
dir()
```

```
##  [1] "classifyMusic.r"     "classifyMusic.Rproj" "corpus.r"           
##  [4] "dtm.r"               "LDA.R"               "precision.r"        
##  [7] "RTextToolssample.r"  "sadsong.csv"         "stopwords.txt"      
## [10] "sweetsong.csv"       "wordCloud.r"         "重复性分析文件.html"
## [13] "重复性分析文件.md"   "重复性分析文件.Rmd"
```



## 读取数据

```r
# 防止读入的所有string都被当成factor
options(stringsAsFactors = FALSE)
# 读入csv文件
Infor.sweet <- read.csv("sweetsong.csv", header = TRUE)
Infor.sad <- read.csv("sadsong.csv", header = TRUE)

# 取歌词lyric进行分析
song.sweet <- Infor.sweet$lyric
song.sad <- Infor.sad$lyric

```


## 形成语料库


```r
library(tm)
library(Rwordseg)
```

```
## Loading required package: rJava
```

```
## # Version: 0.0-4
```

```
## Attaching package: 'Rwordseg'
```

```
## The following object is masked from 'package:tm':
## 
## removeWords
```

```r
## song is a list
corpus <- function(song) {
    
    # 删除英语
    removeEnglish <- function(x) {
        gsub("[a-z]+|[A-Z]+", "", x)
    }
    song <- lapply(song, removeEnglish)
    
    ## 分词
    word <- lapply(song, segmentCN)
    
    ## 形成语料库
    return(Corpus(VectorSource(word)))
    
    
}
# 形成corpus
song.sad.corpus <- corpus(song.sad)
song.sweet.corpus <- corpus(song.sweet)

# 合成甜蜜和伤感的语料库
song.corpus <- c(song.sad.corpus, song.sweet.corpus)
```



## 形成DocumentTermMatrix

```r
dtm <- function(corpus, tfidf = FALSE) {
    ## 文档-词矩阵 词的长度大于1就纳入矩阵 TFIDF minDocFreq
    mystopwords <- readLines("stopwords.txt")
    if (tfidf == TRUE) {
        cor.dtm <- DocumentTermMatrix(corpus, control = list(wordLengths = c(2, 
            4), stopwords = mystopwords, weighting = weightTfIdf))
    } else {
        cor.dtm <- DocumentTermMatrix(corpus, control = list(wordLengths = c(2, 
            4), stopwords = mystopwords))
    }
    ## 去掉稀疏矩阵中低频率的词
    cor.dtm <- removeSparseTerms(cor.dtm, 0.97)
    
    ## 使得每一行至少有一个词不为0 rowTotals <- apply(cor.dtm, 1, sum) cor.dtm
    ## <- cor.dtm[rowTotals > 0]
    return(cor.dtm)
}
song.corpus.dtm <- dtm(song.corpus)
song.corpus.dtm.tfidf <- dtm(song.corpus, tfidf = TRUE)
```



## 对每首歌曲进行标注：1 表示sad 2表示sweet

```r
class <- c(rep(1, 764), rep(2, 861))
class <- as.factor(class)
```



## create a container

```r
library(RTextTools)
```

```
## Loading required package: SparseM
```

```
## Attaching package: 'SparseM'
```

```
## The following object is masked from 'package:base':
## 
## backsolve
```

```
## Loading required package: randomForest
```

```
## randomForest 4.6-7
```

```
## Type rfNews() to see new features/changes/bug fixes.
```

```
## Loading required package: tree
```

```
## Loading required package: nnet
```

```
## Loading required package: e1071
```

```
## Loading required package: class
```

```
## Loading required package: ipred
```

```
## KernSmooth 2.23 loaded Copyright M. P. Wand 1997-2009
```

```
## Loading required package: caTools
```

```
## Loading required package: maxent
```

```
## Loading required package: Rcpp
```

```
## Warning: replacing previous import 'coerce' when loading 'SparseM'
```

```
## Loading required package: glmnet
```

```
## Loading required package: Matrix
```

```
## Loading required package: lattice
```

```
## Attaching package: 'Matrix'
```

```
## The following object is masked from 'package:SparseM':
## 
## det
```

```
## Loaded glmnet 1.9-5
```

```
## Loading required package: tau
```

```
## Warning: replacing previous import 'coerce' when loading 'SparseM'
```

```r
container <- create_container(song.corpus.dtm, class, trainSize = 1:1528, testSize = 1529:1625, 
    virgin = FALSE)
```




## training models

```r
SVM <- train_model(container, "SVM")
GLMNET <- train_model(container, "GLMNET")
MAXENT <- train_model(container, "MAXENT")
SLDA <- train_model(container, "SLDA")
BOOSTING <- train_model(container, "BOOSTING")
BAGGING <- train_model(container, "BAGGING")
RF <- train_model(container, "RF")
TREE <- train_model(container, "TREE")
```



## classifying data using trained models

```r
SVM_CLASSIFY <- classify_model(container, SVM)
GLMNET_CLASSIFY <- classify_model(container, GLMNET)
MAXENT_CLASSIFY <- classify_model(container, MAXENT)
SLDA_CLASSIFY <- classify_model(container, SLDA)
BOOSTING_CLASSIFY <- classify_model(container, BOOSTING)
BAGGING_CLASSIFY <- classify_model(container, BAGGING)
RF_CLASSIFY <- classify_model(container, RF)
NNET_CLASSIFY <- classify_model(container, NNET)
```

```
## Error: object 'NNET' not found
```

```r
TREE_CLASSIFY <- classify_model(container, TREE)
```






## analytics

```r
CLASSIFY <- cbind(SVM_CLASSIFY, SLDA_CLASSIFY, BOOSTING_CLASSIFY, BAGGING_CLASSIFY, 
    RF_CLASSIFY, GLMNET_CLASSIFY, TREE_CLASSIFY, MAXENT_CLASSIFY)
analytics <- create_analytics(container, CLASSIFY)
summary(analytics)
```

```
## ENSEMBLE SUMMARY
## 
##        n-ENSEMBLE COVERAGE n-ENSEMBLE RECALL
## n >= 1                1.00              0.70
## n >= 2                1.00              0.70
## n >= 3                1.00              0.70
## n >= 4                1.00              0.70
## n >= 5                0.92              0.76
## n >= 6                0.76              0.77
## n >= 7                0.59              0.81
## n >= 8                0.30              0.83
## 
## 
## ALGORITHM PERFORMANCE
## 
##        SVM_PRECISION           SVM_RECALL           SVM_FSCORE 
##                    1                    1                    1 
##       SLDA_PRECISION          SLDA_RECALL          SLDA_FSCORE 
##                    1                    1                    1 
## LOGITBOOST_PRECISION    LOGITBOOST_RECALL    LOGITBOOST_FSCORE 
##                    1                    1                    1 
##    BAGGING_PRECISION       BAGGING_RECALL       BAGGING_FSCORE 
##                    1                    1                    1 
##    FORESTS_PRECISION       FORESTS_RECALL       FORESTS_FSCORE 
##                    1                    1                    1 
##     GLMNET_PRECISION        GLMNET_RECALL        GLMNET_FSCORE 
##                    1                    1                    1 
##       TREE_PRECISION          TREE_RECALL          TREE_FSCORE 
##                    1                    1                    1 
## MAXENTROPY_PRECISION    MAXENTROPY_RECALL    MAXENTROPY_FSCORE 
##                    1                    1                    1
```



create_ensembleSummary(analytics@document_summary)

SVM <- cross_validate(container, 10, "SVM")
TREE <- cross_validate(container, 10, "TREE")
MAXENT <- cross_validate(container, 10, "MAXENT")
SLDA <- cross_validate(container, 10, "SLDA")
BOOSTING <- cross_validate(container, 10, "BOOSTING")
BAGGING <- cross_validate(container, 10, "BAGGING")
RF <- cross_validate(container, 10, "RF")
GLMNET <- cross_validate(container, 10, "GLMNET")

# 计算召回率
recall_accuracy(analytics@document_summary$MANUAL_CODE, analytics@document_summary$SVM_LABEL)
recall_accuracy(analytics@document_summary$MANUAL_CODE, analytics@document_summary$SLDA_LABEL)
recall_accuracy(analytics@document_summary$MANUAL_CODE, analytics@document_summary$BAGGING_LABEL)
recall_accuracy(analytics@document_summary$MANUAL_CODE, analytics@document_summary$FORESTS_LABEL)
recall_accuracy(analytics@document_summary$MANUAL_CODE, analytics@document_summary$TREE_LABEL)
recall_accuracy(analytics@document_summary$MANUAL_CODE, analytics@document_summary$GLMNET_LABEL)
recall_accuracy(analytics@document_summary$MANUAL_CODE, analytics@document_summary$MAXENTROPY_LABEL)

precision_recall_f1 <- create_precisionRecallSummary(container, results)
score_summary <- create_scoreSummary(container, results)





# 形成DocTermMatrix
song.sweet.dtm <- dtm(song.sweet)$DocTermMatrix
song.sad.dtm <- dtm(song.sad)$DocTermMatrix

# 画词云

song.sweet.wordcloud <- wordCloud(song.sweet.dtm)
song.sad.wordcloud <- wordCloud(song.sad.dtm)



